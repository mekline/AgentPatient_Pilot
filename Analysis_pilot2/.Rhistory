df.wide$gender[i] = a$questiondata$gender
}
df.wide$age[i] = a$questiondata$age
df.wide$condition[i] = a$condition
df.wide$counterbalance[i] = a$counterbalance
#cycles through the trials
for (j in 1:8){
df.wide[[paste("question_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[1]]
df.wide[[paste("rating_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[2]]
df.wide[[paste("throw_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[4]]
df.wide[[paste("grass_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[6]]
df.wide[[paste("distance_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[8]]
df.wide[[paste("wall_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[10]]
}
df.wide$feedback[i] = a$questiondata$feedback
}
df.long = wideToLong(subset(df.wide,select=-feedback),within="trial")
#create factors
df.long = mutate(df.long, question = as.factor(question),
throw = factor(throw,levels=c("low","high")),
grass = factor(grass,levels=c("low","high")),
distance = factor(distance,levels=c("short","long")),
wall = factor(wall,levels=c("no","yes")),
gender = factor(gender,levels=c("female","male","NA")),
age = as.numeric(age))
df.long = df.long[order(df.long$participant,df.long$question),]
install.packages(c("lsr", "dplyr", "RSQLite"))
# Packages ----------------------------------------------------------------
rm(list=ls())
library(lsr)
library(dplyr)
library(rjson)
library(RSQLite)
# Read data ---------------------------------------------------------------
con = dbConnect(SQLite(),dbname = "participants.db");
df.complete = dbReadTable(con,"almost") #change the name of the database here (mine was called "almost")
dbDisconnect(con)
#filter out incompletes
df.complete = subset(df.complete,status %in% c(3,4))
#save data of different experiments in separate data frames
df.complete.experiment_1 = subset(df.complete,codeversion == "experiment_1")
df.complete.experiment_2 = subset(df.complete,codeversion == "experiment_2")
df.complete.experiment_3 = subset(df.complete,codeversion == "experiment_3")
# EXP1: Structure data ----------------------------------------------------------
df.wide = data.frame(matrix(nrow=nrow(df.complete.experiment_1),ncol=8))
colnames(df.wide) = c("experiment","participant","id","gender","age","condition","counterbalance","feedback")
for (i in 1:nrow(df.wide)){
a = fromJSON(df.complete.experiment_1$datastring[i])
df.wide$experiment[i] = df.complete.experiment_1$codeversion[i]
df.wide$participant[i] = i
df.wide$id[i] = a$workerId
if (is.null(a$questiondata$gender)){df.wide$gender[i] = NA
}else{
df.wide$gender[i] = a$questiondata$gender
}
df.wide$age[i] = a$questiondata$age
df.wide$condition[i] = a$condition
df.wide$counterbalance[i] = a$counterbalance
#cycles through the trials
for (j in 1:8){
df.wide[[paste("question_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[1]]
df.wide[[paste("rating_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[2]]
df.wide[[paste("throw_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[4]]
df.wide[[paste("grass_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[6]]
df.wide[[paste("distance_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[8]]
df.wide[[paste("wall_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[10]]
}
df.wide$feedback[i] = a$questiondata$feedback
}
df.long = wideToLong(subset(df.wide,select=-feedback),within="trial")
#create factors
df.long = mutate(df.long, question = as.factor(question),
throw = factor(throw,levels=c("low","high")),
grass = factor(grass,levels=c("low","high")),
distance = factor(distance,levels=c("short","long")),
wall = factor(wall,levels=c("no","yes")),
gender = factor(gender,levels=c("female","male","NA")),
age = as.numeric(age))
df.long = df.long[order(df.long$participant,df.long$question),]
# Packages ----------------------------------------------------------------
rm(list=ls())
library(lsr)
library(dplyr)
library(rjson)
library(RSQLite)
# Read data ---------------------------------------------------------------
con = dbConnect(SQLite(),dbname = "participants.db");
df.complete = dbReadTable(con,"almost") #change the name of the database here (mine was called "almost")
dbDisconnect(con)
#filter out incompletes
df.complete = subset(df.complete,status %in% c(3,4))
#save data of different experiments in separate data frames
df.complete.experiment_1 = subset(df.complete,codeversion == "experiment_1")
df.complete.experiment_2 = subset(df.complete,codeversion == "experiment_2")
df.complete.experiment_3 = subset(df.complete,codeversion == "experiment_3")
# EXP1: Structure data ----------------------------------------------------------
df.wide = data.frame(matrix(nrow=nrow(df.complete.experiment_1),ncol=8))
colnames(df.wide) = c("experiment","participant","id","gender","age","condition","counterbalance","feedback")
for (i in 1:nrow(df.wide)){
a = fromJSON(df.complete.experiment_1$datastring[i])
df.wide$experiment[i] = df.complete.experiment_1$codeversion[i]
df.wide$participant[i] = i
df.wide$id[i] = a$workerId
if (is.null(a$questiondata$gender)){df.wide$gender[i] = NA
}else{
df.wide$gender[i] = a$questiondata$gender
}
df.wide$age[i] = a$questiondata$age
df.wide$condition[i] = a$condition
df.wide$counterbalance[i] = a$counterbalance
#cycles through the trials
for (j in 1:8){
df.wide[[paste("question_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[1]]
df.wide[[paste("rating_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[2]]
df.wide[[paste("throw_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[4]]
df.wide[[paste("grass_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[6]]
df.wide[[paste("distance_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[8]]
df.wide[[paste("wall_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[10]]
}
df.wide$feedback[i] = a$questiondata$feedback
}
df.long = wideToLong(subset(df.wide,select=-feedback),within="trial")
#create factors
df.long = mutate(df.long, question = as.factor(question),
throw = factor(throw,levels=c("low","high")),
grass = factor(grass,levels=c("low","high")),
distance = factor(distance,levels=c("short","long")),
wall = factor(wall,levels=c("no","yes")),
gender = factor(gender,levels=c("female","male","NA")),
age = as.numeric(age))
df.long = df.long[order(df.long$participant,df.long$question),]
library(dplyr)
install.packages("dplyr")
library(plyr)
# Packages ----------------------------------------------------------------
rm(list=ls())
library(lsr)
library(dplyr)
library(rjson)
library(RSQLite)
# Read data ---------------------------------------------------------------
con = dbConnect(SQLite(),dbname = "participants.db");
df.complete = dbReadTable(con,"almost") #change the name of the database here (mine was called "almost")
dbDisconnect(con)
#filter out incompletes
df.complete = subset(df.complete,status %in% c(3,4))
#save data of different experiments in separate data frames
df.complete.experiment_1 = subset(df.complete,codeversion == "experiment_1")
df.complete.experiment_2 = subset(df.complete,codeversion == "experiment_2")
df.complete.experiment_3 = subset(df.complete,codeversion == "experiment_3")
# EXP1: Structure data ----------------------------------------------------------
df.wide = data.frame(matrix(nrow=nrow(df.complete.experiment_1),ncol=8))
colnames(df.wide) = c("experiment","participant","id","gender","age","condition","counterbalance","feedback")
for (i in 1:nrow(df.wide)){
a = fromJSON(df.complete.experiment_1$datastring[i])
df.wide$experiment[i] = df.complete.experiment_1$codeversion[i]
df.wide$participant[i] = i
df.wide$id[i] = a$workerId
if (is.null(a$questiondata$gender)){df.wide$gender[i] = NA
}else{
df.wide$gender[i] = a$questiondata$gender
}
df.wide$age[i] = a$questiondata$age
df.wide$condition[i] = a$condition
df.wide$counterbalance[i] = a$counterbalance
#cycles through the trials
for (j in 1:8){
df.wide[[paste("question_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[1]]
df.wide[[paste("rating_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[2]]
df.wide[[paste("throw_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[4]]
df.wide[[paste("grass_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[6]]
df.wide[[paste("distance_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[8]]
df.wide[[paste("wall_",j-1,sep="")]][i] =
a$data[[j]]$trialdata[[10]]
}
df.wide$feedback[i] = a$questiondata$feedback
}
df.long = wideToLong(subset(df.wide,select=-feedback),within="trial")
#create factors
df.long = mutate(df.long, question = as.factor(question),
throw = factor(throw,levels=c("low","high")),
grass = factor(grass,levels=c("low","high")),
distance = factor(distance,levels=c("short","long")),
wall = factor(wall,levels=c("no","yes")),
gender = factor(gender,levels=c("female","male","NA")),
age = as.numeric(age))
df.long = df.long[order(df.long$participant,df.long$question),]
library(lsr)
foo <- c(3,12,10,5)
dim(foo) <-c(2,2)
foo
foo <- c(3,12,7,10,5,6)
dim(foo) <-c(3,2)
foo
fisher.test(foo)
foo <- c(10,20,1,20)
dim(foo) <- c(2,2)
foo
chisq.test(foo)
fisher.test(foo)
installed.packages()
binomial.test([1 1 0 0 0 ], 0.5)
binomial.test(c(1 1 0 0 0 ), 0.5)
foo = c(1,2,2,2)
foo = c(0,1,1,1,1)
binomial.test(foo, 0.5)
binom.test(foo, 0.5)
binom.test(1,20,0)
binom.test(1,2000,0)
binom.test(1,2000,0.1)
binom.test(1,2000,0.5)
binom.test(1000,2000,0.5)
binom.test(1,2000,0, alternative="greater")
p = 0.032
p.adjust(p, n=20, method="fdr")
install.packages("rmarkdown")
version()
rversion()
install.packages('installr')
install.packages("installr")
install.packages('updater')
install.package('installr')
install.packages("installr")
install.packages("installr")
libraries
library(ggplot2)
install.packages("ggplot2")
setwd("~/Dropbox/_Projects/TriangleEventsMP - fMRI/EventsMP_Pilot2")
# This file reads in ALL the %-signal-change values, per-participant, per-parcel, per-contrast,
# Those %-signal-change calculations are produced by the awesome toolbox analyses,
# and represent a single overall calculation derived for the whole parcel region
# (not individual voxels, as mk sometimes forgets)
#
# NOTE: This version works for the PL2017 outputs, at least as of 12/24/2017
rm(list = ls())
library(bootstrap)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
##SET YOUR DIRECTORY!!!
########
#READ IN DATA
########
# Add in the contrast and ROI names so it's not just numbers!!!!! (This ordering comes from the
# standard ordering produced by the 2nd level analyses; we'll arrange differently in the plots)
myResults = read.csv('loc_langloc_crit_eventsMP_20171218.csv',
colClasses = c("factor","factor", "factor","numeric","numeric")) %>%
mutate(Localizer = 'langlocSN') %>%
mutate(ROISystem = 'LHLang') %>%
mutate(TaskCrit = 'EventsMP')
allSigChange = read.csv('loc_langloc_crit_langloc_20171218.csv',
colClasses = c("factor","factor", "factor","numeric","numeric")) %>%
mutate(Localizer = 'langlocSN') %>%
mutate(ROISystem = 'LHLang') %>%
mutate(TaskCrit = 'langlocSN')
allSigChange = rbind(allSigChange, myResults)
#########
# TRANSFORMATIONS
#########
avgSigChange = allSigChange %>%
group_by(Subject,Contrast,ROISystem,Localizer,TaskCrit) %>%
summarize('SignalChange' = mean(SignalChange)) %>%
mutate(ROIName = 'Localizer Average') %>%
mutate(nVoxels = 0)
allSigChange <- union(allSigChange, avgSigChange)
#(Gets mad that there's a new ROIName level :p)
allSigChange$ROIName <- as.factor(allSigChange$ROIName)
#Next, get the table that we'll be making the graphs from: for each region (including the average region), take all
#the individual signal changes and calculate a mean, a standard error (incase we want it)
#and bootstrapped CIs (which we'll actually use)
sterr <- function(mylist){
my_se = sd(mylist)/sqrt(length(mylist))
return(my_se)
}
#bootstrapped 95% confidence intervals! calculate them from allSigChange
#then merge into mystats
bootup <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.975)[1])
}
bootdown <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.025)[1])
}
toGraph <- allSigChange %>%
group_by(ROIName, Contrast, Localizer, ROISystem, TaskCrit) %>%
summarize(meanSig = mean(SignalChange), sterr = sterr(SignalChange),
bootup = bootup(SignalChange), bootdown = bootdown(SignalChange))%>%
mutate(ROIGroup = ifelse(ROIName == 'Localizer Average','across ROIs','individual ROIs'))
#Force some factor orderings here, they are finicky!
toGraph$ROIName <- factor(toGraph$ROIName, levels = c("LIFGorb",
"LIFG",
"LMFG",
"LAntTemp",
"LPostTemp",
"LAngG",
"Localizer Average"))
toGraph$ROIGroup <- factor(toGraph$ROIGroup, levels = c("across ROIs",
"individual ROIs"))
toGraph <- toGraph %>%
arrange(ROIGroup, ROIName)
#########
# Graphs!
#########
#Now we can use the information stored in mystats to make pretty graphs! This could be done in excel too by printing mystats
#Change to figs output folder
figdir = paste(getwd(),'figs')
setwd(figdir)
#Subset and rename for language localiser
LangLoc_LangCrit <- filter(toGraph, Localizer =='langlocSN',TaskCrit =='langlocSN') %>%
filter(Contrast %in% c('S','N'))
LangLoc_EvCrit <- filter(toGraph, Localizer =='langlocSN',TaskCrit =='EventsMP') %>%
filter(Contrast %in% c("Cont","DiffAll","SameAll","SameMan","SamePath","SameAg"))
#More factor reordering
LangLoc_LangCrit$Contrast <- factor(LangLoc_LangCrit$Contrast, levels = c("S","N"))
LangLoc_LangCrit <- LangLoc_LangCrit %>%
arrange(ROIGroup, ROIName, Contrast)
LangLoc_EvCrit$Contrast <- factor(LangLoc_EvCrit$Contrast, levels = c("DiffAll","SameMan",
"SamePath","SameAg",
"SameAll","Cont"))
LangLoc_EvCrit <- LangLoc_EvCrit %>%
arrange(ROIGroup, ROIName, Contrast)
#Graphing function!
makeBar = function(plotData, fileName = 'TEST NAME', ylow=-0.5,yhigh=2.5, mycolors = c("gray35", "gray60")) {
#freeze factor orders, AGAIN
plotData$ROIName <- factor(plotData$ROIName, levels = unique(plotData$ROIName))
plotData$ROIGroup <- factor(plotData$ROIGroup, levels = unique(plotData$ROIGroup))
myfi = paste(fileName, '.jpg', sep="")#filename
print(myfi)
ggplot(data=plotData, aes(x=ROIName, y=meanSig, fill=Contrast)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=bootdown, ymax=bootup), colour="black", width=.1, position=position_dodge(.9)) +
coord_cartesian(ylim=c(ylow-0.5,yhigh+0.5)) +
scale_y_continuous(breaks = seq(ylow-0.5, yhigh+0.5, 0.5))+
xlab('') +
ylab(str_wrap('% signal change over fixation', width=18)) +
theme_bw() +
theme(legend.key = element_blank()) +
theme(text = element_text(size = 25)) +
facet_grid(~ROIGroup, scale='free_x', space='free_x') +
theme(strip.background = element_blank()) +
theme(strip.text = element_blank())
ggsave(filename=myfi, width=length(unique(plotData$ROIName))*2.2, height=6.1)
}
makeBar(LangLoc_LangCrit, 'LangLoc_LangCrit')
makeBar(LangLoc_EvCrit, 'LangLoc_EventsMPCrit', yhigh=0.5)
makeBar(LangLoc_EvCrit, 'LangLoc_EventsMPCrit', yhigh=1)
setwd("~/Dropbox/_Projects/AgentPatient - fMRI/AgentPatient_Pilot Repo/Analysis_pilot2")
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the toolbox into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
####
#Stuff to change!
myResultsFolder = paste(getwd(),'/loc_langloc_crit_agpat_20171218',sep='')
myOutputFolder = getwd()
myFilename = 'loc_langloc_crit_agpat_20171218.csv'
toSave = 1
#(Resulting data struct stored in variable myfile, to use directory)
####
# Leave alone unless feeling fancy
library(dplyr)
library(tidyr)
library(stringr)
setwd(myResultsFolder)
#Open the weirdly formatted files (actually they are formatted better now, thanks A.!) and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
names(myfile) = c('ROIName','Subject','Contrast','nVoxels','SignalChange')
if(toSave){
setwd(myOutputFolder)
zz <- file(myFilename, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
# #### Old version, pre PL2017
# #Leave the rest alone unless you're feeling fancy
#
# library(dplyr)
# library(tidyr)
# library(stringr)
#
# setwd(myResultsFolder)
#
# #Open the weirdly formatted files and get just the table we want.
# myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
# lastsub = ncol(myfile)
# myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#
# #To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
# #localizer, provide names for parcels. Also could add all that as an optional function arg.
#
# extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
#   foo = str_split(mystring, "\\.")
#   myval = unlist(foo[[1]][mynum])
#   return(myval)
#
# }
#
# #Make the data beautiful and longform.
# myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
# myfile <- myfile %>%
#   gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
#   rowwise() %>%
#   mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
#   mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
#   select(-Subject_and_Cont) %>%
#   rename(ROI = ROI.)
#
#
# #Optional: print back out a nice file with a more informative name.
# if(toSave){
#   setwd(myOutputFolder)
#   zz <- file(myFilename, "w")
#   write.csv(myfile, zz, row.names=FALSE)
#   close(zz)
# }
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the toolbox into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
####
#Stuff to change!
myResultsFolder = paste(getwd(),'/loc_langloc_crit_langloc_20171218',sep='')
myOutputFolder = getwd()
myFilename = 'loc_langloc_crit_langloc_20171218.csv'
toSave = 1
#(Resulting data struct stored in variable myfile, to use directory)
####
# Leave alone unless feeling fancy
library(dplyr)
library(tidyr)
library(stringr)
setwd(myResultsFolder)
#Open the weirdly formatted files (actually they are formatted better now, thanks A.!) and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
names(myfile) = c('ROIName','Subject','Contrast','nVoxels','SignalChange')
if(toSave){
setwd(myOutputFolder)
zz <- file(myFilename, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
# #### Old version, pre PL2017
# #Leave the rest alone unless you're feeling fancy
#
# library(dplyr)
# library(tidyr)
# library(stringr)
#
# setwd(myResultsFolder)
#
# #Open the weirdly formatted files and get just the table we want.
# myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
# lastsub = ncol(myfile)
# myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#
# #To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
# #localizer, provide names for parcels. Also could add all that as an optional function arg.
#
# extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
#   foo = str_split(mystring, "\\.")
#   myval = unlist(foo[[1]][mynum])
#   return(myval)
#
# }
#
# #Make the data beautiful and longform.
# myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
# myfile <- myfile %>%
#   gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
#   rowwise() %>%
#   mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
#   mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
#   select(-Subject_and_Cont) %>%
#   rename(ROI = ROI.)
#
#
# #Optional: print back out a nice file with a more informative name.
# if(toSave){
#   setwd(myOutputFolder)
#   zz <- file(myFilename, "w")
#   write.csv(myfile, zz, row.names=FALSE)
#   close(zz)
# }
